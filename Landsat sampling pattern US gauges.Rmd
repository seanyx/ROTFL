---
title: "Landsat_sampling_pattern"
author: "Xiao Yang"
date: "8/21/2019"
output: html_document
---

Last update: 12/26/2019

# Load packages and functions

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

require(tidyverse)
require(sf)
require(foreach)

load("outputs/dat_full_discharge_cleaned_20191226.RData", verbose = T)
load("outputs/dat_landsat_discharge_cleaned_20191226.RData", verbose = T)
load("outputs/site_lonlat_20191226.RData", verbose = T)

run_test = function(x, y, test, verbose) {
  if (test == "ks") {
    result = ks.test(x, y, alternative = "two.sided")
    if (verbose) {print(result)}
    pvalue = result$p.value
    statistics = result$statistic
    output = tibble(pvalue, statistics, test_name = "Two-sample Kolmogorov-Smirnov test", method = "ks")
  }
  if (test == "ad") {
    require(kSamples)
    result = ad.test(x, y, method = "asymptotic")
    if (verbose) {print(result)}
    statistics = result$ad[1, 1]
    pvalue = result$ad[1, 3]
    output = tibble(pvalue, statistics, test_name = "Anderson-Darling test", method = "ad")
  }
  if (test == "ks.boot") {
    result = Matching::ks.boot(x, y, alternative = "two.sided")
    if (verbose) {print(result)}
    statistics = result$ks$statistic
    pvalue = result$ks.boot.pvalue
    output = tibble(pvalue, statistics, test_name = "Two-sample Kolmogorov-Smirnov test", method = "ks.boot")
  }
  
  invisible(output)
}

temp_test = function(x, y, verbose = F) {
  ## test to run for each temporal permutation
  ## exports the D value, p value, 0, 10, 20, ..., 100th percentile of both x and y
  
  ## ks test
  result = ks.test(x, y, alternative = "two.sided")
  pvalue = result$p.value
  statistics = result$statistic
  
  percentile = c(0, 0.01, 0.05, 0.5, 0.95, 0.99, 1)
  ps_x = tibble(per = sprintf(as.integer(percentile * 100), fmt = "%03d"), value = quantile(x, probs = percentile, na.rm = T, names = F)) %>% mutate(source = "x") %>% unite(., "pername", source, per, sep = "_") %>% spread(key = pername, value = "value")
  ps_y = tibble(per = sprintf(as.integer(percentile * 100), fmt = "%03d"), value = quantile(y, probs = percentile, na.rm = T, names = F)) %>% mutate(source = "y") %>% unite(., "pername", source, per, sep = "_") %>% spread(key = pername, value = "value")
  
  if (verbose) {print(result)}
  
  ## percentile
  
  output = tibble(pvalue, statistics, nx = length(x), ny = length(y)) %>% 
    bind_cols(ps_x, ps_y)
  
  return(output)
}

temporal_permutation = function(start_date, end_date, n_year, n_permutation) {
  ## define the range possible for the starting date of the temporal sampling
  min_start_date = start_date
  max_start_date = end_date - n_year * 365.25
  
  start_dates = min_start_date + runif(n = n_permutation) * (max_start_date - min_start_date)
  
  return(tibble(start_dates, end_dates = start_dates + n_year * 365.25))
}
```

# Replicate fig3 by George

```{r}
pers = c(0, 1, 5, 10, 50, 90, 95, 99, 100)

dat_full_discharge = dat_full_discharge %>% 
  filter(discharge > 0)

ls_discharge = ls_discharge %>% 
  filter(discharge > 0)

for (i in 1:length(pers)) {
  
  print(pers[i])
  
  temp1 = dat_full_discharge %>% 
    group_by(site_id) %>% 
    summarise(quantiles_gauge = quantile(discharge, probs = pers[i] / 100)) %>% 
    ungroup() %>% 
    mutate(per = as.character(pers[i]))
  
  temp2 = ls_discharge %>% 
    group_by(site_id) %>% 
    summarise(quantiles_ls = quantile(discharge, probs = pers[i] / 100)) %>% 
    ungroup() %>% 
    mutate(per = as.character(pers[i]))
  
  if (i == 1) {
    gauge_pers = temp1
    ls_pers = temp2
  } else if (i != 1) {
      gauge_pers = bind_rows(gauge_pers, temp1)
      ls_pers = bind_rows(ls_pers, temp2)
    }
}

merged = gauge_pers %>% 
  inner_join(ls_pers, by = c("site_id", "per"))

merged = merged %>% 
  mutate(label = factor(per, levels = as.character(pers), labels = paste0("Quantile: ", pers, "%"), ordered = T))

### test error metrics
merged %>% ggplot() + geom_point(aes(x = quantiles_gauge, y = quantiles_ls - quantiles_gauge), pch = 1) + facet_wrap(~label, scales = "free_y") + labs(x = "Qpopulation (cms)", y = "Qsample - Qpopulation (cms)") + scale_x_log10()

# notice the range of y values
merged %>% ggplot() + geom_point(aes(x = quantiles_gauge, y = (quantiles_ls - quantiles_gauge) / quantiles_gauge), pch = 1) + facet_wrap(~label, scales = "free_y") + labs(x = "Qpopulation (cms)", y = "(Qsample - Qpopulation) / Qpopulation") + scale_x_log10()
### end of test

test_result = merged %>% 
  group_by(label) %>% 
  do({
    top = .
    # top = merged %>% filter(per == "0")
    
    ### linear fit
    fit = lm(quantiles_ls ~ quantiles_gauge, data = top)
    b = fit$coefficients[1]
    k = fit$coefficients[2]
    fit_string = paste0("y = ", format(k, digits = 2), "x ", if (abs(b) == b) "+ " else "- ", format(abs(b), digits = 2))
    
    ### sen slope
    fit_sen = zyp::zyp.sen(quantiles_ls ~ quantiles_gauge, data = top)
    b_sen = fit_sen$coefficients[1]
    k_sen = fit_sen$coefficients[2]
    fit_string_sen = paste0("y = ", format(k_sen, digits = 2), "x ", if (abs(b_sen) == b_sen) "+ " else "- ", format(abs(b_sen), digits = 1))
    
    ### for visualization
    fit_sen_log = zyp::zyp.sen(quantiles_ls ~ quantiles_gauge, data = top %>% mutate(quantiles_ls = log10(quantiles_ls), quantiles_gauge = log10(quantiles_gauge)))
    b_sen_log = fit_sen_log$coefficients[1]
    k_sen_log = fit_sen_log$coefficients[2]
    
    ### R2
    r2 = (fit %>% summary)$r.squared
    r2_string = paste0("R2 = ", format(r2, digits = 2))
    
    ### rrmse and rbias
    error_stats = top %>% 
      mutate(dif = quantiles_ls - quantiles_gauge) %>% 
      summarise(rrmse = sqrt(mean((dif / quantiles_gauge)^2)),
                rbias = mean(dif / quantiles_gauge))
    
    rrmse_string = paste0("rRMSE: ", format(error_stats$rrmse, digits = 2))
    rbias_string = paste0("rBias: ", format(error_stats$rbias, digits = 2))
    
    ### ks test
    ks = ks.test(x = top$quantiles_gauge, y = top$quantiles_ls)
    D = ks$statistic
    p = ks$p.value
    ks_D_string = paste0("K-S D: ", format(D, digits = 2))
    ks_pvalue_string = if (p < 0.01) "K-S p < 0.01" else paste0("K-S p: ", format(p, digits = 2))
    
    ### xy lim for plotting text
    xmin = top$quantiles_gauge %>% min
    xmax = top$quantiles_gauge %>% max
    ymin = top$quantiles_ls %>% min
    ymax = top$quantiles_ls %>% max
    
    ### wilcox
    wc = wilcox.test(x = top$quantiles_gauge, y = top$quantiles_ls)
    p = wc$p.value
    wc_pvalue_string = if (p < 0.01) "MWW p < 0.01" else paste0("MWW p: ", format(p, digits = 2))
    
    tibble(meta = paste0(c(fit_string_sen, r2_string, rrmse_string, rbias_string,
           ks_D_string, wc_pvalue_string), collapse = "\n"), b_sen = b_sen, k_sen = k_sen, xmin, xmax, ymin, ymax)
  }) %>% 
  ungroup()

## test values from first calculating metrics for individual gauge
merged %>% 
  filter(quantiles_gauge != 0,
         quantiles_ls != 0) %>% 
  mutate(bias = quantiles_ls - quantiles_gauge,
         relative_bias = bias / quantiles_gauge) %>% 
  ggplot() +
  geom_histogram(aes(relative_bias), binwidth = 0.01) + 
  xlim(0, 1) +
  facet_wrap(~label)
  

fig3 = merged %>% 
  ggplot(aes(x = quantiles_gauge, y = quantiles_ls)) +
  geom_abline(aes(slope = 1, intercept = 0), color = "black", lwd = 0.5) +
  geom_point(size = 1, alpha = 0.4, pch = 1) +
  geom_abline(data = test_result, aes(intercept = b_sen, slope = k_sen), color = "red") +
  # geom_smooth(method = lm, color = "red", lwd = 0.25, fullrange = T) +
  # geom_text(data = test_result, aes(x = 1e3, y = 1e-2, label = meta), size = 7 * 0.35, hjust = 0, vjust = 0) +
  geom_text(data = test_result, aes(x = xmax * 0.65, y = 1e-3, label = meta), size = 7 * 0.35, hjust = 0, vjust = 0) +
  # scale_x_log10() +
  # scale_y_log10() +
  # scale_x_log10(limits = c(1e-2, 1e6)) +
  # scale_y_log10(limits = c(1e-2, 1e6)) +
  # coord_equal() +
  labs(x = "Qpopulation (cms)",
       y = "Qsample (cms)") +
  facet_wrap(~label, ncol = 3, scales = "free") +
  theme(panel.background = element_blank(),
        panel.grid = element_blank(),
        panel.border = element_rect(fill = NA),
        strip.text = element_text(face = "bold"))

fig3

fig3 %>% 
  ggsave(filename = "figs/fig3_sen_slope_linear_scale.png",
         width = 7.5,
         height = 7.5,
         dpi = "print")

fig3 %>% 
  ggsave(filename = "figs/fig3_sen_slope_linear_scale.pdf",
         width = 7.5,
         height = 7.5,
         dpi = "print")
```

## test shift function approach

```{r}
this_site_id = "01010000"

x = dat_full_discharge %>% 
  filter(site_id == this_site_id) %>% 
  pull(discharge)

y = ls_discharge %>% 
  filter(site_id == this_site_id,
         cloud_free) %>% 
  pull(discharge)

levels = c(0, 0.01, 0.1, 0.5, 0.9, 0.99, 1)
t1 = Sys.time()
test = qcomhd(x = y, y = x, nboot = 100, q = levels, plotit = F)
print(Sys.time() - t1)

test %>% 
  mutate(q = factor(q, levels = levels, labels = paste0(levels * 100, "%"))) %>% 
  ggplot() + 
  geom_errorbar(aes(x = q, ymin = ci.low, ymax = ci.up)) + 
  geom_line(aes(x = 1:7, y = est.1_minus_est.2), color = "grey") + 
  geom_point(aes(x = q, y = est.1_minus_est.2)) +
  labs(x = "Quantiles",
       y = "Qsample - Qpopulation (cms)")

sampled_ids = dat_full_discharge %>% 
  select(site_id) %>% 
  distinct()# %>% sample_n(1)

t1 = Sys.time()
test_msites = sampled_ids %>% 
  group_by(site_id) %>% 
  do({
    dat = .
    this_site_id = dat$site_id[1]
    
    x = dat_full_discharge %>% 
      filter(site_id == this_site_id) %>% 
      pull(discharge)
    
    y = ls_discharge %>% 
      filter(site_id == this_site_id,
             cloud_free) %>% 
      pull(discharge)
    
    levels = c(0, 0.01, 0.1, 0.5, 0.9, 0.99, 1)
    # t1 = Sys.time()
    qcomhd(x = y, y = x, nboot = 100, q = levels, SEED = T, plotit = F) %>% 
      as_tibble()
    # print(Sys.time() - t1)
  }) %>% 
  ungroup()
print(Sys.time() - t1)

save(test_msites, file = "outputs/test_msites.RData")

# test_msites %>% 
#   mutate(q = factor(q, levels = levels, labels = paste0(levels * 100, "%"))) %>% 
#   ggplot() + 
#   geom_errorbar(aes(x = q, ymin = ci.low, ymax = ci.up)) + 
#   # geom_line(aes(x = 1:7, y = est.1_minus_est.2), color = "grey") + 
#   geom_point(aes(x = q, y = est.1_minus_est.2)) +
#   labs(x = "Quantiles",
#        y = "Qsample - Qpopulation (cms)") +
#   facet_wrap(~site_id, scales = "free_y")

test_msites %>% 
  mutate(q = factor(q, levels = levels, labels = paste0(levels * 100, "%"))) %>% 
  ggplot() + 
  geom_bar(aes(x = q, fill = signif))

test_msites %>% 
  mutate(q = factor(q, levels = levels, labels = paste0(levels * 100, "%"))) %>% 
  ggplot() + 
  geom_bar(aes(x = q, fill = ci.low * ci.up >= 0))



id = "03253500"
ls_discharge %>% filter(site_id == id) %>% nrow()
ggplot() +
  geom_density(data = dat_full_discharge %>% filter(site_id == id), aes(discharge, fill = "full"), alpha = 0.5) +
  geom_density(data = ls_discharge %>% filter(site_id == id), aes(discharge, fill = "ls"), alpha = 0.5) +
  scale_x_log10()
```



# Temporal test

## One gauge

```{r}
id = "09070000"

# id = dat_full_discharge %>% 
#   dplyr::select(site_id) %>% 
#   distinct() %>% 
#   sample_n(100) %>% 
#   pull

print(id)

q_all = dat_full_discharge %>% filter(site_id == id)
q_ls_cf = ls_discharge %>% filter(site_id == id, cloud_free)

gauge_start_date = q_all$date %>% min()
gauge_end_date = q_all$date %>% max()
lscf_start_date = q_ls_cf$date %>% min()
lscf_end_date = q_ls_cf$date %>% max()

start_date = max(gauge_start_date, lscf_start_date)
end_date = min(gauge_end_date, lscf_end_date)

years = 1:10

test = foreach(i = years, .combine = "bind_rows") %do% {
  dates = temporal_permutation(start_date, end_date, n_year = i, n_permutation = 30)
  dates %>% 
    mutate(index = 1:nrow(.)) %>% 
    group_by(index) %>% 
    do({
      temp = .
      
      ## compare ls discharge with gauge daily discharge for the same i year period
      # sub_q_all = q_all %>% filter(date >= temp$start_dates[1], date <= temp$end_dates[1]) %>% pull(discharge)
      # sub_q_lscf = q_ls_cf %>% filter(date >= temp$start_dates[1], date <= temp$end_dates[1]) %>% pull(discharge)
      
      ## compare ls discharge with gauge daily discharge (other than the landsat dates) for the same i year period
      ls_dates = q_ls_cf %>% filter(date >= temp$start_dates[1], date <= temp$end_dates[1]) %>% pull(date)
      gauge_dates = q_all %>% filter(date >= temp$start_dates[1], date <= temp$end_dates[1]) %>% pull(date)
      diff_dates = tibble(date = as.Date(setdiff(gauge_dates, ls_dates), origin = "1970-01-01"))
      sub_q_all = q_all %>% right_join(diff_dates, by = "date") %>% pull(discharge)
      sub_q_lscf = q_ls_cf %>% right_join(tibble(date = ls_dates), by = "date") %>% pull(discharge)
      
      temp_test(x = sub_q_all, y = sub_q_lscf, verbose = F) %>% 
        mutate(nyear = i)
    }) %>% 
    ungroup()
}

test %>% 
  ggplot() + 
  geom_boxplot(aes(x = nyear, y = statistics, group = nyear))

test %>% 
  ggplot() + 
  geom_boxplot(aes(x = nyear, y = pvalue, group = nyear))


```

## All gauges that having temporal range of both Landsat sampling and gauge records greater than 15 years

1. Calculate for each gauge the duration of available flow data;
2. For gauges having greater than 15 years of both gauge and Landsat data (N = 927), randomly generate 50 intervals within N year duration (N = 1, 2, 3, ..., 10), for each pair of flow data conducted K-S test and caclulated quantile values at 0%, 1%, 5%, 10%, 50%, 90%, 95%, 99%, and 100%;

### 1 & 2
```{r}
n_years_gauge = dat_full_discharge %>% 
  group_by(site_id) %>% 
  summarise(n_max_year = floor(as.integer(max(date) - min(date)) / 365.25)) %>% 
  ungroup()

n_years_landsat = ls_discharge %>% 
  filter(cloud_free) %>% 
  group_by(site_id) %>% 
  summarise(n_max_year = floor(as.integer(max(date) - min(date)) / 365.25)) %>% 
  ungroup()

gauge_id_temporal_analysis = n_years_gauge %>% 
  filter(n_max_year >= 15) %>% 
  inner_join(n_years_landsat %>% 
               filter(n_max_year >= 15), by = "site_id") %>% 
  select(site_id) %>% 
  distinct()

N_sites = nrow(gauge_id_temporal_analysis)

## default value when no values returned when filtering records to a given duration
default_test = tibble(pvalue = NA, statistics = NA, nx = -999, ny = -999)

for (j in 1:N_sites) {
  
  id = gauge_id_temporal_analysis$site_id[j]
  
  print(paste("starting task", j, "of", N_sites, ": ", id))
  
  q_all = dat_full_discharge %>% filter(site_id == id) ## daily discharge data at gauge
  q_ls_cf = ls_discharge %>% filter(site_id == id, cloud_free) ## discharge data observed by LS when cloud free
  
  ## calculate temporal intersection between ranges from gauge and Landsat
  gauge_start_date = q_all$date %>% min()
  gauge_end_date = q_all$date %>% max()
  lscf_start_date = q_ls_cf$date %>% min()
  lscf_end_date = q_ls_cf$date %>% max()
  
  start_date = max(gauge_start_date, lscf_start_date)
  end_date = min(gauge_end_date, lscf_end_date)
  
  ## for each given temporal interval (in years), generate random intervals to compare the discharge from gauge and observed by Landsat
  years = 1:10
  temp_dat = foreach(i = years, .combine = "bind_rows") %do% {
    
    dates = temporal_permutation(start_date, end_date, n_year = i, n_permutation = 50) ## generate N = 50 random intervals
    
    dates %>% 
      mutate(index = 1:nrow(.)) %>% 
      group_by(index) %>% 
      do({
        temp = .
        
        ## compare ls discharge with gauge daily discharge for the same i year period
        sub_q_all = q_all %>% filter(date >= temp$start_dates[1], date <= temp$end_dates[1]) %>% pull(discharge)
        sub_q_lscf = q_ls_cf %>% filter(date >= temp$start_dates[1], date <= temp$end_dates[1]) %>% pull(discharge)
        
        ## if either of sub_q_all or sub_q_lscf were 0, return the default value of the test result then remove them afterwards
        if (length(sub_q_all) == 0 | length(sub_q_lscf) == 0) {
          default_test %>% mutate(nyear = -999)
        } else {
          temp_test(x = sub_q_all, y = sub_q_lscf, verbose = F) %>% 
            mutate(nyear = i)
        }
        
      }) %>% 
      ungroup()
  } %>% 
    select(-index) %>% 
    mutate(site_id = id)
  
  if(j == 1) {
    output = temp_dat
  } else if (j != 1) {
    output = bind_rows(output, temp_dat)
  }
}

save(output, file = "outputs/output_temporal_analysis_not_exclude_landsat_dates_permu50_newBreakpoint.RData")
```

### Relationship between comparison and years of observations
```{r }
load("outputs/output_temporal_analysis_not_exclude_landsat_dates_permu50_newBreakpoint.RData", verbose = T)

output = output %>% 
  filter(nyear != -999) %>% 
  distinct() %>% 
  mutate(n_day_miss_per_year = ((nx) - nyear * 365.25) / nyear) # estimate how many days were missing for one year 
  # filter(n_day_miss_per_year >= -30)

## to assign permutation index
output = output %>% group_by(nyear, site_id) %>% mutate(perm_index = 1:n()) %>% ungroup()

## how many sites included in the analysis
output %>% 
  select(site_id) %>% 
  distinct()

## relationship between median D and nyears
### 1. for each interval length and for each gauge, calculate the median D values
### 2. plot the median value against the interval length
fig_d_nyear = output %>% 
  # filter(n_day_miss_per_year >= -30) %>% 
  group_by(nyear, site_id) %>% 
  summarise(D_median = median(statistics)) %>% 
  ungroup() %>% 
  mutate(nyear = as.factor(nyear)) %>% 
  ggplot() +
  geom_boxplot(aes(nyear, D_median, group = nyear)) +
  labs(
    x = "Landsat observation interval (years)",
    y = "Median D value"
  ) +
  theme(panel.background = element_blank(),
        panel.border = element_rect(fill = NA, colour = "grey"))

fig_d_nyear

fig_d_nyear %>% 
  ggsave(filename = "figs/fig_d_nyear_permu50.png",
         width = 3.74,
         height = 3.75,
         dpi = 300)

# output %>% 
#   group_by(nyear, site_id) %>% 
#   summarise(p_median = median(pvalue)) %>% 
#   ungroup() %>% 
#   mutate(nyear = as.factor(nyear)) %>% 
#   ggplot() +
#   geom_boxplot(aes(nyear, p_median, group = nyear)) +
#   labs(
#     x = "Years of Landsat observation",
#     y = "Per site median p value"
#   )

output_long = output[, c(5:11, 19, 22)] %>% 
  gather(key = "per", value = "x_value", -c(nyear, perm_index)) %>% 
  bind_cols(
    output[, c(12:18)] %>% 
      gather(key = "y_per", value = "y_value")) %>% 
  select(-y_per) %>% 
  separate(per, into = c(NA, "percentile"), sep = "_")

output_long %>% ggplot() +geom_bar(aes(x = perm_index, fill = percentile), position = "dodge")

# save(output_long, file = "outputs/output_long_not_exclude_landsat_dates_new_breakPoints.RData")

load("outputs/output_long_not_exclude_landsat_dates_new_breakPoints.RData", verbose = T)

# pernames = seq(0, 100, by = 10) %>% sprintf(fmt = "%03d")
# 
# for (i in 1:length(pernames)) {
#   
#   output_long_fil = output_long %>% 
#     filter(percentile == pernames[i])
#   
#   error = output_long_fil %>% 
#     mutate(diffyx = y_value - x_value) %>% 
#     group_by(nyear) %>% 
#     summarise(
#       `Mean bias` = mean(diffyx),
#       `Mean absolute error` = mean(abs(diffyx)),
#       `mRMSE` = sqrt(mean(diffyx^2)) / (max(x_value) - min(x_value))
#     ) %>% 
#     ungroup %>% 
#     gather(key = "metric", value = "value", -nyear)
#   
#   error_fig = error %>% 
#     filter(metric == "mRMSE") %>% 
#     ggplot() +
#     geom_line(aes(x = nyear, y = value, color = metric)) +
#     geom_point(aes(x = nyear, y = value, color = metric)) +
#     scale_x_continuous(breaks = seq(1, 10, by = 1)) +
#     labs(
#       x = "Years of observation",
#       y = paste0("Error value (", as.integer(pernames[i]), "th percentile)"),
#       color = "Error metrics"
#     ) +
#     theme(legend.position = c(0.8, 0.8))
#   
#   error_fig %>% 
#     ggsave(filename = paste0("figs/summary_figure/", "error_fig_percentile_", pernames[i], ".png"),
#            width = 5,
#            height = 5)
#     
#   fig = output_long_fil %>% 
#     mutate(nyear = factor(paste(nyear, "year(s) of obs"), ordered = T)) %>% 
#     ggplot() +
#     # geom_hex(aes(x = x_value, y = y_value, fill = log(..count..))) +
#     geom_abline(aes(slope = 1, intercept = 0), color = "red") +
#     geom_point(aes(x = x_value, y = y_value), alpha = 0.1, size = 0.1) +
#     scale_fill_viridis_c() +
#     scale_x_log10() +
#     scale_y_log10() +
#     labs(
#       x = paste0(as.integer(pernames[i]), "th percentile discharge (Gauge sampled)"),
#       y = paste0(as.integer(pernames[i]), "th percentile discharge (Landsat sampled)")
#     ) +
#     facet_wrap(~nyear, ncol = 4)
#   
#   fig %>% 
#     ggsave(filename = paste0("figs/summary_figure/", "xy_fig_percentile_", pernames[i], ".png"),
#            width = 10,
#            height = 7)
# }

output_long = output_long %>% 
  mutate(x_value = x_value * 0.0283168,
         y_value = y_value * 0.0283168)

error_perm = output_long %>% 
    filter(x_value != 0,
           y_value != 0) %>% 
    mutate(diffyx = y_value - x_value) %>% 
    group_by(nyear, percentile, perm_index) %>% 
    summarise(
      Bias = mean(diffyx),
      rBias = mean(diffyx / x_value, na.rm = T),
      MAE = mean(abs(diffyx)),
      rMAE = mean(abs(diffyx / x_value), na.rm = T),
      RMSE = sqrt(mean((diffyx)^2)),
      rRMSE = sqrt(mean((diffyx / x_value)^2)),
      R2 = (lm(y_value ~ x_value) %>% summary)$r.squared
    ) %>% 
  ungroup

boxplot_fig = error_perm %>% mutate(nyear = as.factor(nyear)) %>% ggplot() + geom_boxplot(aes(x = nyear, y = R2, fill = percentile)) + labs(x = "Years of observation", y = "R2", fill = "Discharge percentile")

boxplot_fig

boxplot_fig %>% ggsave(filename = "figs/temporal_sampling.png", width = 7, height = 5)

error_perm %>% filter(nyear == 1) %>% ggplot() + geom_point(aes(x = percentile, R2))

error = error_perm %>% 
  group_by(nyear, percentile) %>% 
  summarise(Bias = median(Bias),
            rBias = median(rBias),
            MAE = median(MAE),
            rMAE = median(rMAE),
            RMSE = median(RMSE),
            rRMSE = median(rRMSE),
            R2 = median(R2)) %>% 
  ungroup() %>% 
  gather(key = "metric", value = "value", -c(nyear, percentile))

abs_error_fig = error %>% 
  # filter(metric %in% c("rBias", "rMAE", "rRMSE")) %>%
  filter(metric %in% c("Bias", "MAE", "RMSE")) %>%
  ggplot(aes(x = nyear, y = value)) +
  geom_line(aes(color = percentile)) +
  geom_point(aes(color = percentile)) +
  # scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  scale_x_continuous(breaks = seq(1, 10, by = 1)) +
  labs(x = "Years of observation",
       y = "Discharge (cms)",
       color = "Discharge\npercentile") +
  facet_wrap(~metric, scales = "free_y") +
  theme(panel.background = element_rect(fill = "white"),
        panel.grid.major = element_line(color = "lightgrey"),
        panel.border = element_rect(fill = NA),
        strip.text = element_text(face = "bold"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        axis.title.y = element_blank())
  
abs_error_fig

abs_error_fig %>% 
  ggsave(filename = "figs/relative_error_permu50_fig_absolute_error_corrected.png",
         width = 6,
         height = 3,
         dpi = 300)

rel_error_fig = error %>% 
  filter(metric %in% c("rBias", "rMAE", "rRMSE")) %>%
  ggplot(aes(x = nyear, y = value)) +
  geom_line(aes(color = percentile)) +
  geom_point(aes(color = percentile)) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  scale_x_continuous(breaks = seq(1, 10, by = 1)) +
  labs(x = "Years of observation",
       y = "",
       color = "Discharge\npercentile") +
  facet_wrap(~metric, scales = "free_y") +
  theme(panel.background = element_rect(fill = "white"),
        panel.grid.major = element_line(color = "lightgrey"),
        panel.border = element_rect(fill = NA),
        strip.text = element_text(face = "bold"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        axis.title.y = element_blank())
  
rel_error_fig

rel_error_fig %>% 
  ggsave(filename = "figs/relative_error_permu50_fig_relative_error_corrected.png",
         width = 6,
         height = 3,
         dpi = 300)

r2_error_fig = error %>% 
  # filter(metric %in% c("rBias", "rMAE", "rRMSE")) %>%
  filter(metric %in% c("R2")) %>%
  ggplot(aes(x = nyear, y = value)) +
  geom_line(aes(color = percentile)) +
  geom_point(aes(color = percentile)) +
  # scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  scale_x_continuous(breaks = seq(1, 10, by = 1)) +
  labs(x = "Years of observation",
       y = "",
       color = "Discharge\npercentile") +
  facet_wrap(~metric, scales = "free_y") +
  theme(panel.background = element_rect(fill = "white"),
        panel.grid.major = element_line(color = "lightgrey"),
        panel.border = element_rect(fill = NA),
        strip.text = element_text(face = "bold"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        axis.title.y = element_blank())

r2_error_fig

r2_error_fig %>% 
  ggsave(filename = "figs/relative_error_permu50_fig_r2_error_newsize_corrected.png",
         width = 3.5,
         height = 4,
         dpi = 300)

pvalue_boxplot = output %>% 
  ggplot() + 
  geom_boxplot(aes(x = nyear, y = pvalue, group = nyear)) +
  labs(
    x = "Years of observation",
    y = "K-S pvalue"
  ) +
  theme(panel.background = element_rect(fill = "white"),
        panel.grid.major = element_line(color = "white"),
        panel.border = element_rect(fill = NA),
        strip.text = element_text(face = "bold"),
        legend.position = "bottom",
        legend.direction = "horizontal",
axis.title.y = element_blank())

pvalue_boxplot

pvalue_boxplot %>% 
  ggsave(
    filename = "figs/pvalue_boxplot.png",
    width = 3,
    height = 3,
    dpi = 300
  )
```



### Relationship between comparison and years of observations
```{r }
load("outputs/output_temporal_analysis_not_exclude_landsat_dates_permu50_newBreakpoint.RData", verbose = T)

output = output %>% 
  filter(nyear != -999) %>% 
  distinct() %>% 
  mutate(n_day_miss_per_year = ((nx) - nyear * 365.25) / nyear) # estimate how many days were missing for one year 
  # filter(n_day_miss_per_year >= -30)

## how many sites included in the analysis
output %>% 
  select(site_id) %>% 
  distinct()

## relationship between median D and nyears
### 1. for each interval length and for each gauge, calculate the median D values
### 2. plot the median value against the interval length
fig_d_nyear = output %>% 
  # filter(n_day_miss_per_year >= -30) %>% 
  group_by(nyear, site_id) %>% 
  summarise(D_median = median(statistics)) %>% 
  ungroup() %>% 
  mutate(nyear = as.factor(nyear)) %>% 
  ggplot() +
  geom_boxplot(aes(nyear, D_median, group = nyear)) +
  labs(
    x = "Landsat observation interval (years)",
    y = "Median D value"
  ) +
  theme(panel.background = element_blank(),
        panel.border = element_rect(fill = NA, colour = "grey"))

fig_d_nyear

fig_d_nyear %>% 
  ggsave(filename = "figs/fig_d_nyear_permu50.png",
         width = 3.74,
         height = 3.75,
         dpi = 300)

# output %>% 
#   group_by(nyear, site_id) %>% 
#   summarise(p_median = median(pvalue)) %>% 
#   ungroup() %>% 
#   mutate(nyear = as.factor(nyear)) %>% 
#   ggplot() +
#   geom_boxplot(aes(nyear, p_median, group = nyear)) +
#   labs(
#     x = "Years of Landsat observation",
#     y = "Per site median p value"
#   )

output_long = output[, c(5:11, 19)] %>% 
  gather(key = "per", value = "x_value", -c(nyear)) %>% 
  bind_cols(
    output[, c(12:18)] %>% 
      gather(key = "y_per", value = "y_value")) %>% 
  select(-y_per) %>% 
  separate(per, into = c(NA, "percentile"), sep = "_")

# save(output_long, file = "outputs/output_long_not_exclude_landsat_dates_new_breakPoints.RData")

load("outputs/output_long_not_exclude_landsat_dates_new_breakPoints.RData", verbose = T)

# pernames = seq(0, 100, by = 10) %>% sprintf(fmt = "%03d")
# 
# for (i in 1:length(pernames)) {
#   
#   output_long_fil = output_long %>% 
#     filter(percentile == pernames[i])
#   
#   error = output_long_fil %>% 
#     mutate(diffyx = y_value - x_value) %>% 
#     group_by(nyear) %>% 
#     summarise(
#       `Mean bias` = mean(diffyx),
#       `Mean absolute error` = mean(abs(diffyx)),
#       `mRMSE` = sqrt(mean(diffyx^2)) / (max(x_value) - min(x_value))
#     ) %>% 
#     ungroup %>% 
#     gather(key = "metric", value = "value", -nyear)
#   
#   error_fig = error %>% 
#     filter(metric == "mRMSE") %>% 
#     ggplot() +
#     geom_line(aes(x = nyear, y = value, color = metric)) +
#     geom_point(aes(x = nyear, y = value, color = metric)) +
#     scale_x_continuous(breaks = seq(1, 10, by = 1)) +
#     labs(
#       x = "Years of observation",
#       y = paste0("Error value (", as.integer(pernames[i]), "th percentile)"),
#       color = "Error metrics"
#     ) +
#     theme(legend.position = c(0.8, 0.8))
#   
#   error_fig %>% 
#     ggsave(filename = paste0("figs/summary_figure/", "error_fig_percentile_", pernames[i], ".png"),
#            width = 5,
#            height = 5)
#     
#   fig = output_long_fil %>% 
#     mutate(nyear = factor(paste(nyear, "year(s) of obs"), ordered = T)) %>% 
#     ggplot() +
#     # geom_hex(aes(x = x_value, y = y_value, fill = log(..count..))) +
#     geom_abline(aes(slope = 1, intercept = 0), color = "red") +
#     geom_point(aes(x = x_value, y = y_value), alpha = 0.1, size = 0.1) +
#     scale_fill_viridis_c() +
#     scale_x_log10() +
#     scale_y_log10() +
#     labs(
#       x = paste0(as.integer(pernames[i]), "th percentile discharge (Gauge sampled)"),
#       y = paste0(as.integer(pernames[i]), "th percentile discharge (Landsat sampled)")
#     ) +
#     facet_wrap(~nyear, ncol = 4)
#   
#   fig %>% 
#     ggsave(filename = paste0("figs/summary_figure/", "xy_fig_percentile_", pernames[i], ".png"),
#            width = 10,
#            height = 7)
# }

output_long = output_long %>% 
  mutate(x_value = x_value * 0.0283168,
         y_value = y_value * 0.0283168)

error = output_long %>% 
    filter(x_value != 0,
           y_value != 0) %>% 
    mutate(diffyx = y_value - x_value) %>% 
    group_by(nyear, percentile) %>% 
    summarise(
      Bias = mean(diffyx),
      rBias = mean(diffyx / x_value, na.rm = T),
      MAE = mean(abs(diffyx)),
      rMAE = mean(abs(diffyx / x_value), na.rm = T),
      RMSE = sqrt(mean((diffyx)^2)),
      rRMSE = sqrt(mean((diffyx / x_value)^2)),
      R2 = (lm(y_value ~ x_value) %>% summary)$r.squared
    ) %>% 
    ungroup %>% 
    gather(key = "metric", value = "value", -c(nyear, percentile))

abs_error_fig = error %>% 
  # filter(metric %in% c("rBias", "rMAE", "rRMSE")) %>%
  filter(metric %in% c("Bias", "MAE", "RMSE")) %>%
  ggplot(aes(x = nyear, y = value)) +
  geom_line(aes(color = percentile)) +
  geom_point(aes(color = percentile)) +
  # scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  scale_x_continuous(breaks = seq(1, 10, by = 1)) +
  labs(x = "Years of observation",
       y = "Discharge (cms)",
       color = "Discharge\npercentile") +
  facet_wrap(~metric, scales = "free_y") +
  theme(panel.background = element_rect(fill = "white"),
        panel.grid.major = element_line(color = "lightgrey"),
        panel.border = element_rect(fill = NA),
        strip.text = element_text(face = "bold"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        axis.title.y = element_blank())
  
abs_error_fig

abs_error_fig %>% 
  ggsave(filename = "figs/relative_error_permu50_fig_absolute_error.png",
         width = 6,
         height = 3,
         dpi = 300)

rel_error_fig = error %>% 
  filter(metric %in% c("rBias", "rMAE", "rRMSE")) %>%
  ggplot(aes(x = nyear, y = value)) +
  geom_line(aes(color = percentile)) +
  geom_point(aes(color = percentile)) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  scale_x_continuous(breaks = seq(1, 10, by = 1)) +
  labs(x = "Years of observation",
       y = "",
       color = "Discharge\npercentile") +
  facet_wrap(~metric, scales = "free_y") +
  theme(panel.background = element_rect(fill = "white"),
        panel.grid.major = element_line(color = "lightgrey"),
        panel.border = element_rect(fill = NA),
        strip.text = element_text(face = "bold"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        axis.title.y = element_blank())
  
rel_error_fig

rel_error_fig %>% 
  ggsave(filename = "figs/relative_error_permu50_fig_relative_error.png",
         width = 6,
         height = 3,
         dpi = 300)

r2_error_fig = error %>% 
  # filter(metric %in% c("rBias", "rMAE", "rRMSE")) %>%
  filter(metric %in% c("R2")) %>%
  ggplot(aes(x = nyear, y = value)) +
  geom_line(aes(color = percentile)) +
  geom_point(aes(color = percentile)) +
  # scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  scale_x_continuous(breaks = seq(1, 10, by = 1)) +
  labs(x = "Years of observation",
       y = "",
       color = "Discharge\npercentile") +
  facet_wrap(~metric, scales = "free_y") +
  theme(panel.background = element_rect(fill = "white"),
        panel.grid.major = element_line(color = "lightgrey"),
        panel.border = element_rect(fill = NA),
        strip.text = element_text(face = "bold"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        axis.title.y = element_blank())

r2_error_fig

r2_error_fig %>% 
  ggsave(filename = "figs/relative_error_permu50_fig_r2_error_newsize.png",
         width = 3.5,
         height = 4,
         dpi = 300)

pvalue_boxplot = output %>% 
  ggplot() + 
  geom_boxplot(aes(x = nyear, y = pvalue, group = nyear)) +
  labs(
    x = "Years of observation",
    y = "K-S pvalue"
  ) +
  theme(panel.background = element_rect(fill = "white"),
        panel.grid.major = element_line(color = "white"),
        panel.border = element_rect(fill = NA),
        strip.text = element_text(face = "bold"),
        legend.position = "bottom",
        legend.direction = "horizontal",
axis.title.y = element_blank())

pvalue_boxplot

pvalue_boxplot %>% 
  ggsave(
    filename = "figs/pvalue_boxplot.png",
    width = 3,
    height = 3,
    dpi = 300
  )
```

### Define D value to map the gauges

Gave up for D evaluation can be unstable when there was few discharge data from Landsat overpassing
```{r}
load("outputs/output_temporal_analysis_not_exclude_landsat_dates_permu50_newBreakpoint.RData", verbose = T)

output = output %>% 
  filter(nyear != -999) %>% 
  distinct() %>% 
  mutate(n_day_miss_per_year = ((nx) - nyear * 365.25) / nyear)

output %>% 
  group_by(nyear, site_id) %>% 
  summarise(medianD = mean(statistics)) %>% 
  ungroup %>% 
  mutate(nyear = as.factor(nyear)) %>% 
  # filter(nyear == 1) %>% 
  ggplot() +
  geom_line(aes(x = nyear, y = medianD, group = site_id), lwd = 0.5, alpha = 0.2)

output_long %>% 
  ggplot() +
  geom_boxplot()

output %>% 
  filter(site_id == "01030500") %>% 
  ggplot() +
  geom_boxplot(aes(x = nyear, y = statistics, group = nyear)) +
  geom_hline(aes(yintercept = 0.1), color = "red")

output_long2 = output[, c(5:11, 19, 20)] %>% 
  gather(key = "per", value = "x_value", -c(nyear, site_id)) %>% 
  separate(per, into = c(NA, "percentile"), sep = "_") %>% 
  inner_join(
    output[, c(12:18, 19, 20)] %>% 
      gather(key = "per", value = "y_value", -c(nyear, site_id)) %>% 
      separate(per, into = c(NA, "percentile"), sep = "_")
    , by = c("nyear", "site_id", "percentile"))

output_long2 %>% 
  filter(site_id == "01030500") %>% 
  group_by(percentile, nyear) %>% 
  summarise(x_median = median(x_value),
            y_median = median(y_value)) %>% 
  ungroup() %>% 
  mutate(nyear = as.factor(nyear)) %>% 
  ggplot() +
  geom_line(aes(x = x_median, y = y_median, group = nyear), color = "grey") +
  geom_point(aes(x = x_median, y = y_median, color = nyear, group = nyear)) +
  scale_color_viridis_d()

output_long2 %>% 
  filter(site_id == "01030500") %>% 
  mutate(nyear = as.factor(nyear)) %>% 
  # gather(key = "source", value = "value", -c(percentile, site_id, nyear)) %>% 
  ggplot() +
  geom_density(aes(x = y_value - x_value, fill = percentile), alpha = 0.3) +
  facet_wrap(~nyear, scales = "free") +
  scale_y_log10()
```


### scatter plot comparing values at different combinations of observation interval and discharge quantile
```{r}
load("outputs/output_long_not_exclude_landsat_dates_new_breakPoints.RData", verbose = T)

### calculate scatter plot

output_long = output_long %>% 
  filter(x_value != 0,
         y_value != 0) %>% 
  mutate(x_value = x_value * 0.0283168,
         y_value = y_value * 0.0283168)

output_long = output_long %>% 
  mutate(percentile_label = paste0("Quantile: ", as.integer(percentile), "%"))

summary_stats = output_long %>% 
  group_by(nyear, percentile, percentile_label) %>% 
  do({
    top = . 
    
    top = top %>% 
      rename(quantiles_gauge = x_value,
             quantiles_ls = y_value)
    # top = merged %>% filter(per == "0")
    
    ### linear fit
    fit = lm(quantiles_ls ~ quantiles_gauge, data = top)
    b = fit$coefficients[1]
    k = fit$coefficients[2]
    fit_string = paste0("y = ", format(k, digits = 2), "x ", if (abs(b) == b) "+ " else "- ", format(abs(b), digits = 2))
    
    ### rrmse and rbias
    error_stats = top %>% 
      mutate(dif = quantiles_ls - quantiles_gauge) %>% 
      summarise(rrmse = sqrt(mean((dif / quantiles_gauge)^2)),
                rbias = mean(dif / quantiles_gauge))
    
    rrmse_string = paste0("rRMSE: ", format(error_stats$rrmse, digits = 2))
    rbias_string = paste0("rBias: ", format(error_stats$rbias, digits = 2))
    
    ### ks test
    ks = ks.test(x = top$quantiles_gauge, y = top$quantiles_ls)
    D = ks$statistic
    p = ks$p.value
    ks_D_string = paste0("K-S D: ", format(D, digits = 2))
    ks_pvalue_string = if (p < 0.01) "K-S p < 0.01" else paste0("K-S p: ", format(p, digits = 2))
    
    ### wilcox
    wc = wilcox.test(x = top$quantiles_gauge, y = top$quantiles_ls)
    p = wc$p.value
    wc_pvalue_string = if (p < 0.01) "Wilcox p < 0.01" else paste0("Wilcox p: ", format(p, digits = 2))
    
    tibble(meta1 = paste0(c(fit_string, rrmse_string, rbias_string), collapse = "\n"),
           meta2 = paste0(c(ks_D_string, ks_pvalue_string, wc_pvalue_string), collapse = "\n"))
  }) %>% 
  ungroup() %>% 
  filter(percentile %in% c("001", "005", "050", "095", "099"),
         nyear %in% c(1, 2, 3, 5, 10)) %>% 
  mutate(nyear = factor(paste(sprintf(nyear, fmt = "%02d"), "year(s) of obs"), ordered = T))
  

selected_percentiles = output_long %>% 
  filter(percentile %in% c("001", "005", "050", "095", "099"),
         nyear %in% c(1, 2, 3, 5, 10)) %>% 
  mutate(nyear = factor(paste(sprintf(nyear, fmt = "%02d"), "year(s) of obs"), ordered = T)) %>% 
  ggplot() +
    # geom_hex(aes(x = x_value, y = y_value, fill = log(..count..))) +
    geom_abline(aes(slope = 1, intercept = 0), color = "black", lwd = 0.25) +
    geom_point(aes(x = x_value, y = y_value), alpha = 0.3, size = 1, pch = 1) +
  geom_smooth(aes(x = x_value, y = y_value), lwd = 0.5, color = "red", method = lm, fullrange = T) +
  geom_text(data = summary_stats, aes(x = 1e-2, y = 1e6, label = meta1), size = 7 * 0.35, hjust = 0, vjust = 1) +
    geom_text(data = summary_stats, aes(x = 1e2, y = 1e-2, label = meta2), size = 7 * 0.35, hjust = 0, vjust = 0) +
    scale_fill_viridis_c() +
    scale_x_log10(limit = c(1e-2, 1e6)) +
    scale_y_log10(limit = c(1e-2, 1e6)) +
  coord_equal() +
    labs(
      x = "Qpopulation (cms)",
      y = "Qsample (cms)"
    ) +
    facet_grid(percentile_label~nyear) +
    theme(panel.background = element_blank(),
        panel.grid = element_blank(),
        panel.border = element_rect(fill = NA),
        strip.text = element_text(face = "bold"))

selected_percentiles

selected_percentiles %>% 
  ggsave(filename = "figs/selected_percentile_permu_new50_stats.png",
         width = 8,
         height = 8,
         dpi = 300)
```

## change point map

```{r}
load("outputs/output_temporal_analysis_not_exclude_landsat_dates.RData", verbose = T)

output %>% select(site_id)

output %>% filter(site_id == "01010000") %>% select(nyear, statistics, site_id)

output %>% filter(site_id == "01042500") %>% 
  ggplot() +
  geom_boxplot(aes(x = nyear, y = statistics, group = nyear))

output %>% 
  group_by(site_id) %>% 
  summarise(nyear_distinct = length(unique(nyear))) %>% 
  ungroup() %>% 
  ggplot() +
  geom_histogram(aes(x = nyear_distinct))

sites_with_10distinct_years = output %>% 
  group_by(site_id) %>% 
  summarise(nyear_distinct = length(unique(nyear))) %>% 
  ungroup() %>% 
  filter(nyear_distinct == 10) %>% 
  select(site_id)

## one example time series for change detection
require(strucchange)
test = output %>% filter(site_id == "06652000") %>% group_by(nyear) %>% summarise(D_median = median(statistics)) %>% ungroup()

test_ts = ts(test$D_median, start = 1, end = 10)

fs = Fstats(test_ts ~ 1, from = 0.05, to = 0.95)
breakpoint = breakpoints(fs)
plot(test_ts, type = "b", pch = 20)
lines(breakpoint)

bp_table = output %>% 
  right_join(sites_with_10distinct_years, by = "site_id") %>% 
  group_by(site_id, nyear) %>% 
  summarise(D_median = median(statistics)) %>% 
  ungroup() %>% 
  group_by(site_id) %>% 
  do({
    dat = .
    test_ts = ts(dat$D_median, start = 1, end = 10)
    fs = Fstats(test_ts ~ 1, from = 0.05, to = 0.95)
    breakpoint = breakpoints(fs)
    tibble(bp = breakpoint$breakpoints)
  }) %>% 
  ungroup()

bp_table %>% filter(bp <= 5) %>% arrange(desc(bp))

bp_dist = bp_table %>% 
  mutate(bp = as.factor(bp)) %>% 
  ggplot() +
  geom_bar(aes(x = bp), stat = "count") +
  labs(
    x = "Break point (years)",
    y = "Count"
  )
bp_dist
bp_dist %>% 
  ggsave(filename = "figs/bp_dist.png",
         width = 5,
         height = 4,
         dpi = 300)

load("outputs/site_lonlat_20191001.RData", verbose = T)
bp_map = site_lonlat %>% 
  right_join(bp_table, by = "site_id") %>% 
  st_as_sf(coords = c("lon", "lat"), crs = 4326) %>% 
  ggplot() +
  geom_sf(data = st_as_sf(maps::map(database = "world", fill = T, plot = F)), fill = "white", color = "black") +
  geom_sf(aes(color = bp), alpha = 0.7) +
  coord_sf(xlim = c(-125, -66), ylim = c(24, 50)) +
  scale_colour_viridis_c(limits = c(2, 8)) +
  labs(
    color = "Break point\nyear"
  )

bp_map
bp_map %>% 
  ggsave(filename = "figs/bp_map.png",
         width = 7,
         height = 4,
         dpi = 300)


# output
set.seed(2019)
bp_examples = bp_table %>% 
  group_by(bp) %>% 
  sample_n(1) %>% 
  ungroup() %>% 
  left_join(output, by = "site_id") %>% 
  ggplot() +
  geom_vline(aes(xintercept = bp, color = "Break point")) +
  geom_boxplot(aes(x = nyear, y = statistics, group = nyear)) +
  facet_wrap(~site_id, scales = "free_y") +
  scale_x_continuous(breaks = 1:10) +
  labs(x = "Number of years",
       y = "D", 
       color = "")

bp_examples

bp_examples %>% 
  ggsave(filename = "figs/bp_examples.png",
         width = 7,
         height = 6,
         dpi = 300)
```


<!-- ## test on one gauge -->

<!-- ```{r} -->
<!-- id = "09070000" -->

<!-- # id = dat_full_discharge %>%  -->
<!-- #   dplyr::select(site_id) %>%  -->
<!-- #   distinct() %>%  -->
<!-- #   sample_n(100) %>%  -->
<!-- #   pull -->

<!-- print(id) -->

<!-- q_all = dat_full_discharge %>% filter(site_id == id) -->
<!-- q_ls_all = ls_discharge %>% filter(site_id == id) -->
<!-- # q_ls_cf = q_ls_all %>% filter(cloud_free) -->

<!-- test_ks = run_test(q_all$discharge, q_ls_all$discharge, test = "ks", verbose = F) -->
<!-- test_ks_boot = run_test(q_all$discharge, q_ls_all$discharge, test = "ks.boot", verbose = F) -->
<!-- test_ad = run_test(q_all$discharge, q_ls_all$discharge, test = "ad", verbose = F) -->

<!-- tests = bind_rows(test_ks, test_ks_boot, test_ad) %>%  -->
<!--   mutate(diff = pvalue <= 0.05, -->
<!--          result = factor(diff, levels = c(TRUE, FALSE), labels = c("Different", "Not Different"))) -->

<!-- require(gridExtra) -->
<!-- site_fig = ggplot() + -->
<!--   geom_density(data = q_all, aes(x = discharge, fill = "gauge_all"), alpha = 0.5) + -->
<!--   geom_density(data = q_ls_all, aes(x = discharge, fill = "landsat_all"), alpha = 0.5) + -->
<!--   annotation_custom(tableGrob(tests %>% dplyr::select(method, result), rows = NULL)) + -->
<!--   scale_x_log10() + -->
<!--   labs( -->
<!--     x = "Discharge", -->
<!--     y = "Density", -->
<!--     fill = "Data", -->
<!--     title = id, -->
<!--     subtitle = paste0("N_gauge: ", nrow(q_all), "\nN_landsat: ", nrow(q_ls_all)) -->
<!--   ) -->

<!-- site_fig -->

<!-- ``` -->


<!-- ## test on all gauges -->

<!-- ```{r} -->

<!-- ids = dat_full_discharge %>%  -->
<!--   group_by(site_id) %>%  -->
<!--   count() %>%  -->
<!--   ungroup() %>%  -->
<!--   arrange(n) %>%  -->
<!--   dplyr::select(site_id) %>%  -->
<!--   pull -->

<!-- N = ids %>% length -->

<!-- t1 = Sys.time() -->
<!-- for (i in 1:N) { -->

<!--   print(paste0("processing ", i, " of ", N)) -->
<!--   id = ids[i] -->

<!--   q_all = dat_full_discharge %>% filter(site_id == id) -->
<!--   q_ls_all = ls_discharge %>% filter(site_id == id) -->
<!--   # q_ls_cf = q_ls_all %>% filter(cloud_free) -->

<!--   test_ks = run_test(q_all$discharge, q_ls_all$discharge, test = "ks", verbose = F) -->
<!--   test_ks_boot = run_test(q_all$discharge, q_ls_all$discharge, test = "ks.boot", verbose = F) -->
<!--   test_ad = run_test(q_all$discharge, q_ls_all$discharge, test = "ad", verbose = F) -->

<!--   tests = bind_rows(test_ks, test_ks_boot, test_ad) %>%  -->
<!--     mutate(diff = pvalue <= 0.05, -->
<!--            result = factor(diff, levels = c(TRUE, FALSE), labels = c("Different", "Not Different"))) %>%  -->
<!--     mutate(site_id = id) -->

<!--   if (i == 1) { -->
<!--     output = tests -->
<!--   } else if (i > 1) { -->
<!--     output = bind_rows(output, tests) -->
<!--   } -->

<!--   require(gridExtra) -->
<!--   density = ggplot() + -->
<!--     geom_density(data = q_all, aes(x = discharge, fill = "gauge_all"), alpha = 0.5) + -->
<!--     geom_density(data = q_ls_all, aes(x = discharge, fill = "landsat_all"), alpha = 0.5) + -->
<!--     # annotation_custom(tableGrob(tests %>% dplyr::select(method, result, pvalue), rows = NULL)) + -->
<!--     scale_x_log10() + -->
<!--     labs( -->
<!--       x = "Discharge", -->
<!--       y = "Density", -->
<!--       fill = "Data", -->
<!--       title = id, -->
<!--       subtitle = paste0("N_gauge: ", nrow(q_all), "\nN_lands at: ", nrow(q_ls_all)) -->
<!--     ) -->

<!--   table = tableGrob(tests %>% dplyr::select(method, result, pvalue), rows = NULL) -->

<!--   site_fig = grid.arrange(density, table, ncol = 1, heights = c(5, 1)) -->

<!--   site_fig %>%  -->
<!--     ggsave( -->
<!--       filename = paste0("figs/dist_comp_gauge_landsat/", sprintf(i, fmt = "%04d"), "_", id, ".png"), -->
<!--       width = 8, -->
<!--       height = 8, -->
<!--       dpi = 300) -->
<!-- } -->

<!-- save(output, file = "outputs/output_all_gauge.RData") -->

<!-- print(paste("time taken", Sys.time() - t1)) -->



<!-- t1 = Sys.time() -->
<!-- for (i in 1:N) { -->

<!--   print(paste0("processing ", i, " of ", N)) -->
<!--   id = ids[i] -->

<!--   q_all = dat_full_discharge %>% filter(site_id == id) %>% pull(discharge) -->
<!--   q_ls_all = ls_discharge %>% filter(site_id == id) %>% pull(discharge) -->
<!--   q_ls_cf = ls_discharge %>% filter(site_id == id, cloud_free) %>% pull(discharge) -->

<!--   q100 = quantile(q_all, probs = seq(0, 1, length = 101)) -->
<!--   q100_ls_all = quantile(q_ls_all, probs = seq(0, 1, length = 101)) -->
<!--   q100_ls_cf = quantile(q_ls_cf, probs = seq(0, 1, length = 101)) -->

<!--   lm_ls_all = lm(q100_ls_all~q100) -->
<!--   lm_ls_cf = lm(q100_ls_cf~q100) -->

<!--   k_ls_all = lm_ls_all$coefficients[2] -->
<!--   r2_ls_all = summary(lm_ls_all)$r.squared -->

<!--   k_ls_cf = lm_ls_cf$coefficients[2] -->
<!--   r2_ls_cf = summary(lm_ls_cf)$r.squared -->

<!--   tests = tibble(site_id = id, k_ls_all, r2_ls_all, k_ls_cf, r2_ls_cf) -->

<!--   if (i == 1) { -->
<!--     output2 = tests -->
<!--   } else if (i > 1) { -->
<!--     output2 = bind_rows(output2, tests) -->
<!--   } -->

<!-- } -->


<!-- output2 %>%  -->
<!--   left_join(output, by = "site_id") %>%  -->
<!--   ggplot() + -->
<!--   geom_point(aes(x = r2_ls_all, y = pvalue), alpha = 0.3) + -->
<!--   scale_x_log10() + -->
<!--   facet_wrap(~method) -->

<!-- output2 %>%  -->
<!--   left_join(output, by = "site_id") %>%  -->
<!--   ggplot() + -->
<!--   geom_point(aes(x = k_ls_all, y = pvalue), alpha = 0.3) + -->
<!--   facet_wrap(~method) -->
<!-- ``` -->


<!-- ### map the test results -->

<!-- ```{r} -->
<!-- n_ls = ls_discharge %>%  -->
<!--   group_by(site_id) %>%  -->
<!--   count() %>%  -->
<!--   ungroup -->

<!-- output %>%  -->
<!--   filter(method != "ks.boot") %>%  -->
<!--   group_by(site_id) %>%  -->
<!--   summarise(consistent = factor(diff %>% unique %>% length, levels = 1:2, labels = c("Consistent", "Inconsistent"))) %>%  -->
<!--   ungroup() %>%  -->
<!--   filter(consistent == "Inconsistent") %>%  -->
<!--   left_join(n_ls) %>%  -->
<!--   arrange(n) -->

<!-- ``` -->

<!-- ## test on one site with permutation on the starting date -->

<!-- ```{r} -->
<!-- calc_temporal_permutations = function(min_start_date, max_start_date, seed = 2019, N = 30) { -->
<!--   set.seed(seed) -->

<!--   return(tibble(possible_start_dates = seq.Date(from = min_start_date, to = max_start_date, by = 1)) %>%  -->
<!--     sample_n(N) %>%  -->
<!--       pull(possible_start_dates)) -->
<!-- } -->

<!-- ks_stats = function(x, y) { -->
<!--   temp = Matching::ks.boot(x, y, nboots = 100) -->
<!--   return(tibble(D = temp$ks$statistic,  -->
<!--                 p.value = temp$ks$p.value, -->
<!--                 ks.boot.pvalue = temp$ks.boot.pvalue)) -->
<!-- } -->

<!-- this_site_id = "01010000" -->
<!-- this_site_id = "02236125" -->
<!-- # this_site_id = "14211720" -->

<!-- q_gauge = dat_full_discharge %>%  -->
<!--   filter(site_id == this_site_id) -->

<!-- q_ls_all = ls_discharge %>%  -->
<!--   filter(site_id == this_site_id) -->

<!-- q_ls_cf = q_ls_all %>%  -->
<!--   filter(cloud_free) -->

<!-- datemin = q_ls_all$date %>% min() -->
<!-- datemax = q_ls_all$date %>% max() -->

<!-- end_dates = seq.Date(from = datemin, to = datemax, by = 365)[-1] -->

<!-- min_start_date = datemin -->
<!-- max_start_date = datemax - 15 * 365 -->
<!-- potential_start_date = calc_temporal_permutations(min_start_date, max_start_date) -->
<!-- max_years_ls = 15 -->

<!-- t1 = Sys.time() -->
<!-- test_ensemble = foreach(s = 1:length(potential_start_date), .combine = "bind_rows") %do% { -->

<!--   foreach(n = 1:max_years_ls, .combine = "bind_rows") %do% { -->

<!--     this_start_date = potential_start_date[s] -->
<!--     this_end_date = potential_start_date[s] + n * 365 -->

<!--     # q_gauge_fil = q_gauge %>%  -->
<!--     #   filter(date >= this_start_date, -->
<!--     #          date <= this_end_date) -->

<!--     q_ls_all_fil = q_ls_all %>%  -->
<!--       filter(date >= this_start_date, -->
<!--              date <= this_end_date) -->

<!--     q_ls_cf_fil = q_ls_cf %>%  -->
<!--       filter(date >= this_start_date, -->
<!--              date <= this_end_date) -->

<!--     ks_none = tibble( -->
<!--       D = NA, -->
<!--       p.value = NA, -->
<!--       ks.boot.pvalue = NA -->
<!--     ) -->

<!--     if (nrow(q_ls_cf_fil) > 0) { -->
<!--       ks_cf = ks_stats(x = q_ls_cf_fil$discharge,  -->
<!--                        y = q_gauge$discharge) %>%  -->
<!--         mutate(type = "ls_cloud_free") -->
<!--     } else { -->
<!--       ks_cf = ks_none %>%  -->
<!--         mutate(type = "ls_cloud_free") -->
<!--     } -->

<!--     if (nrow(q_ls_all_fil) > 0) { -->
<!--       ks_all = ks_stats(x = q_ls_all_fil$discharge,  -->
<!--                        y = q_gauge$discharge) %>%  -->
<!--         mutate(type = "ls_all_return") -->
<!--     } else { -->
<!--       ks_all = ks_none %>%  -->
<!--         mutate(type = "ls_all_return") -->
<!--     } -->

<!--     ks_all %>%  -->
<!--       bind_rows(ks_cf) %>%  -->
<!--       mutate(nyears = n,  -->
<!--              start_date = this_start_date, -->
<!--              end_date = this_end_date) -->
<!--   } -->

<!-- } -->
<!-- print(paste0("time elapsed: ", Sys.time() - t1)) -->

<!-- test_ensemble = test_ensemble %>%  -->
<!--   mutate(nyears = as.factor(nyears)) -->

<!-- D_fig = test_ensemble %>%  -->
<!--   ggplot() +  -->
<!--   geom_boxplot(aes(x = nyears, y = D, fill = type), alpha = 0.4, show.legend = F) + -->
<!--   labs( -->
<!--     x = "No. of years of Landsat data", -->
<!--     y = "D", -->
<!--     title = this_site_id -->
<!--   ) -->

<!-- D_fig -->

<!-- D_fig %>% -->
<!--   ggsave( -->
<!--     filename = paste0("figs/ksboot/", this_site_id, "_D.png"), -->
<!--     width = 5, -->
<!--     height = 4) -->

<!-- boot_pvalue_fig = test_ensemble %>%  -->
<!--   ggplot() +  -->
<!--   geom_boxplot(aes(x = nyears, y = ks.boot.pvalue, fill = type), alpha = 0.4) + -->
<!--   labs( -->
<!--     fill = "Landsat sampling", -->
<!--     x = "No. of years of Landsat data", -->
<!--     y = "p-value", -->
<!--     title = this_site_id -->
<!--   ) + -->
<!--   theme(legend.direction = "horizontal", -->
<!--         legend.position = "bottom") -->

<!-- boot_pvalue_fig -->

<!-- boot_pvalue_fig %>% -->
<!--   ggsave( -->
<!--     filename = paste0("figs/ksboot/", this_site_id, "_boot_pvalue.png"), -->
<!--     width = 5, -->
<!--     height = 4) -->

<!-- pvalue_fig = test_ensemble %>%  -->
<!--   ggplot() +  -->
<!--   geom_boxplot(aes(x = nyears, y = p.value, fill = type), alpha = 0.4) + -->
<!--   labs( -->
<!--     fill = "Landsat sampling", -->
<!--     x = "No. of years of Landsat data", -->
<!--     y = "p-value", -->
<!--     title = this_site_id -->
<!--   ) + -->
<!--   theme(legend.direction = "horizontal", -->
<!--         legend.position = "bottom") -->

<!-- pvalue_fig -->

<!-- pvalue_fig %>% -->
<!--   ggsave( -->
<!--     filename = paste0("figs/ksboot/", this_site_id, "_pvalue.png"), -->
<!--     width = 5, -->
<!--     height = 4) -->
<!-- ``` -->


<!-- ## test on 100 sites with permutation on the starting date -->

<!-- ```{r} -->
<!-- calc_temporal_permutations = function(min_start_date, max_start_date, seed = 2019, N = 30) { -->
<!--   set.seed(seed) -->

<!--   return(tibble(possible_start_dates = seq.Date(from = min_start_date, to = max_start_date, by = 1)) %>%  -->
<!--     sample_n(N) %>%  -->
<!--       pull(possible_start_dates)) -->
<!-- } -->

<!-- ks_stats = function(x, y) { -->
<!--   temp = Matching::ks.boot(x, y, nboots = 50) -->
<!--   return(tibble(D = temp$ks$statistic,  -->
<!--                 p.value = temp$ks$p.value, -->
<!--                 ks.boot.pvalue = temp$ks.boot.pvalue)) -->
<!-- } -->

<!-- set.seed(2019) -->
<!-- sites100 = dat_full_discharge %>%  -->
<!--   select(site_id) %>%  -->
<!--   distinct() %>%  -->
<!--   sample_n(100) %>%  -->
<!--   pull(site_id) -->

<!-- for (i in 51:100) { -->

<!--   this_site_id = sites100[i] -->

<!--   q_gauge = dat_full_discharge %>%  -->
<!--     filter(site_id == this_site_id) -->

<!--   q_ls_all = ls_discharge %>%  -->
<!--     filter(site_id == this_site_id) -->

<!--   q_ls_cf = q_ls_all %>%  -->
<!--     filter(cloud_free) -->

<!--   datemin = q_ls_all$date %>% min() -->
<!--   datemax = q_ls_all$date %>% max() -->

<!--   end_dates = seq.Date(from = datemin, to = datemax, by = 365)[-1] -->

<!--   min_start_date = datemin -->
<!--   max_start_date = datemax - 15 * 365 -->

<!--   if (min_start_date >= max_start_date) next -->

<!--   potential_start_date = calc_temporal_permutations(min_start_date, max_start_date) -->
<!--   max_years_ls = 15 -->

<!--   t1 = Sys.time() -->
<!--   tmp_ensemble = foreach(s = 1:length(potential_start_date), .combine = "bind_rows") %do% { -->

<!--     foreach(n = 1:max_years_ls, .combine = "bind_rows") %do% { -->

<!--       this_start_date = potential_start_date[s] -->
<!--       this_end_date = potential_start_date[s] + n * 365 -->

<!--       # q_gauge_fil = q_gauge %>%  -->
<!--       #   filter(date >= this_start_date, -->
<!--       #          date <= this_end_date) -->

<!--       q_ls_all_fil = q_ls_all %>%  -->
<!--         filter(date >= this_start_date, -->
<!--                date <= this_end_date) -->

<!--       q_ls_cf_fil = q_ls_cf %>%  -->
<!--         filter(date >= this_start_date, -->
<!--                date <= this_end_date) -->

<!--       ks_none = tibble( -->
<!--         D = NA, -->
<!--         p.value = NA, -->
<!--         ks.boot.pvalue = NA -->
<!--       ) -->

<!--       if (nrow(q_ls_cf_fil) > 0) { -->
<!--         ks_cf = ks_stats(x = q_ls_cf_fil$discharge,  -->
<!--                          y = q_gauge$discharge) %>%  -->
<!--           mutate(type = "ls_cloud_free") -->
<!--       } else { -->
<!--         ks_cf = ks_none %>%  -->
<!--           mutate(type = "ls_cloud_free") -->
<!--       } -->

<!--       if (nrow(q_ls_all_fil) > 0) { -->
<!--         ks_all = ks_stats(x = q_ls_all_fil$discharge,  -->
<!--                          y = q_gauge$discharge) %>%  -->
<!--           mutate(type = "ls_all_return") -->
<!--       } else { -->
<!--         ks_all = ks_none %>%  -->
<!--           mutate(type = "ls_all_return") -->
<!--       } -->

<!--       ks_all %>%  -->
<!--         bind_rows(ks_cf) %>%  -->
<!--         mutate(nyears = n,  -->
<!--                start_date = this_start_date, -->
<!--                end_date = this_end_date, -->
<!--                site_id = this_site_id) -->
<!--     } -->

<!--   } -->
<!--   if (i != 1) { -->
<!--     result = bind_rows(result, tmp_ensemble) -->
<!--   } else if (i == 1) { -->
<!--     result = tmp_ensemble -->
<!--   } -->
<!--   print(paste0("time elapsed for station ", i, ": ", Sys.time() - t1)) -->
<!-- } -->

<!-- # save(result, file = "outputs/tmp_result_100sites.RData") -->
<!-- ``` -->

<!-- ## map the difference -->

<!-- ```{r} -->
<!-- result = result %>%  -->
<!--   mutate(nyears = factor(nyears)) %>%  -->
<!--   filter(!is.na(ks.boot.pvalue)) # remove those with no landsat obs -->

<!-- ratio_sig_diff = result %>%  -->
<!--   group_by(site_id, nyears, type) %>%  -->
<!--   summarise(r_sig_diff_test = sum(ks.boot.pvalue <= 0.05) / n(), -->
<!--             n = n()) %>%  -->
<!--   ungroup() -->

<!-- set.seed(2019) -->
<!-- D_fig = result %>%  -->
<!--   select(site_id) %>%  -->
<!--   distinct() %>%  -->
<!--   sample_n(9) %>%  -->
<!--   left_join(result) %>%  -->
<!--   left_join(ratio_sig_diff) %>%  -->
<!--   ggplot() + -->
<!--   geom_boxplot(aes(x = nyears, y = D, lty = type, fill = r_sig_diff_test * 100)) + -->
<!--   facet_wrap(~site_id, scale = "free_y") + -->
<!--   scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 50, limits = c(0, 100), guide = guide_colorbar(title.position = "top", title.hjust = 0.5, barwidth = unit(80, units = "mm"), barheight = unit(5, units = "mm"), direction = "horizontal")) + -->
<!--   scale_linetype_discrete(guide = guide_legend(title.position = "top", title.hjust = 0.5, direction = "vertical")) + -->
<!--   theme(legend.position = "bottom") + -->
<!--   labs(x = "Number of years of Landsat observation", -->
<!--        y = "D value", -->
<!--        fill = "% of ks.boot tests\nshowing significant (p < 0.05) difference", -->
<!--        lty = "Cloud filter") -->

<!-- D_fig -->

<!-- D_fig %>%  -->
<!--   ggsave(filename = "figs/D_fig9.png", -->
<!--          width = 8, -->
<!--          height = 6) -->


<!-- set.seed(2019) -->
<!-- result %>%  -->
<!--   select(site_id) %>%  -->
<!--   distinct() %>%  -->
<!--   sample_n(9) %>%  -->
<!--   left_join(result) %>% -->
<!--   ggplot() + -->
<!--   geom_boxplot(aes(x = nyears, y = ks.boot.pvalue, fill = type)) + -->
<!--   facet_wrap(~site_id) -->
<!-- ``` -->

<!-- ## test on 100 sites with permutation on the starting date comparing subset of daily gauge data with entire gauge data records -->

<!-- ```{r} -->
<!-- calc_temporal_permutations = function(min_start_date, max_start_date, seed = 2019, N = 30) { -->
<!--   set.seed(seed) -->

<!--   return(tibble(possible_start_dates = seq.Date(from = min_start_date, to = max_start_date, by = 1)) %>%  -->
<!--     sample_n(N) %>%  -->
<!--       pull(possible_start_dates)) -->
<!-- } -->

<!-- ks_stats = function(x, y, test) { -->
<!--   if (test == "ks.boot") { -->
<!--     temp = Matching::ks.boot(x, y, nboots = 50) -->
<!--     return(tibble(D = temp$ks$statistic,  -->
<!--                   p.value = temp$ks$p.value, -->
<!--                   ks.boot.pvalue = temp$ks.boot.pvalue)) -->
<!--   } -->

<!--   if (test == "wilcox.test") { -->
<!--     temp = wilcox.test(x, y) -->
<!--     return(tibble(D = temp$statistic,  -->
<!--                   ks.boot.pvalue = temp$p.value)) -->
<!--   } -->

<!-- } -->

<!-- set.seed(2019) -->
<!-- sites100 = dat_full_discharge %>%  -->
<!--   select(site_id) %>%  -->
<!--   distinct() %>%  -->
<!--   sample_n(100) %>%  -->
<!--   pull(site_id) -->

<!-- for (i in 1:9) { -->

<!--   this_site_id = sites100[i] -->

<!--   q_gauge = dat_full_discharge %>%  -->
<!--     filter(site_id == this_site_id) -->

<!--   # q_gauge_sub = ls_discharge %>%  -->
<!--   #   filter(site_id == this_site_id) -->
<!--   #  -->
<!--   # q_ls_cf = q_ls_all %>%  -->
<!--   #   filter(cloud_free) -->

<!--   datemin = q_gauge$date %>% min() -->
<!--   datemax = q_gauge$date %>% max() -->

<!--   end_dates = seq.Date(from = datemin, to = datemax, by = 365)[-1] -->

<!--   min_start_date = datemin -->
<!--   max_start_date = datemax - 15 * 365 -->

<!--   if (min_start_date >= max_start_date) next -->

<!--   potential_start_date = calc_temporal_permutations(min_start_date, max_start_date) -->
<!--   max_years_ls = 15 -->

<!--   t1 = Sys.time() -->
<!--   tmp_ensemble = foreach(s = 1:length(potential_start_date), .combine = "bind_rows") %do% { -->

<!--     foreach(n = 1:max_years_ls, .combine = "bind_rows") %do% { -->

<!--       this_start_date = potential_start_date[s] -->
<!--       this_end_date = potential_start_date[s] + n * 365 -->

<!--       # q_gauge_fil = q_gauge %>%  -->
<!--       #   filter(date >= this_start_date, -->
<!--       #          date <= this_end_date) -->

<!--       q_gauge_fil = q_gauge %>%  -->
<!--         filter(date >= this_start_date, -->
<!--                date <= this_end_date) -->

<!--       # q_ls_all_fil = q_ls_all %>%  -->
<!--       #   filter(date >= this_start_date, -->
<!--       #          date <= this_end_date) -->
<!--       #  -->
<!--       # q_ls_cf_fil = q_ls_cf %>%  -->
<!--       #   filter(date >= this_start_date, -->
<!--       #          date <= this_end_date) -->

<!--       ks_none = tibble( -->
<!--         D = NA, -->
<!--         p.value = NA, -->
<!--         ks.boot.pvalue = NA -->
<!--       ) -->

<!--       if (nrow(q_gauge_fil) > 0) { -->
<!--         ks_sub_gauge = ks_stats(x = q_gauge_fil$discharge,  -->
<!--                          y = q_gauge$discharge) %>%  -->
<!--           mutate(type = "sub_gauge") -->
<!--       } else { -->
<!--         ks_sub_gauge = ks_none %>%  -->
<!--           mutate(type = "ls_cloud_free") -->
<!--       } -->

<!--       ks_sub_gauge %>%  -->
<!--         mutate(nyears = n,  -->
<!--                start_date = this_start_date, -->
<!--                end_date = this_end_date, -->
<!--                site_id = this_site_id) -->
<!--     } -->

<!--   } -->
<!--   if (i != 1) { -->
<!--     subgauge = bind_rows(subgauge, tmp_ensemble) -->
<!--   } else if (i == 1) { -->
<!--     subgauge = tmp_ensemble -->
<!--   } -->
<!--   print(paste0("time elapsed for station ", i, ": ", Sys.time() - t1)) -->
<!-- } -->


<!-- for (i in 1:9) { -->

<!--   this_site_id = sites100[i] -->

<!--   q_gauge = dat_full_discharge %>%  -->
<!--     filter(site_id == this_site_id) -->

<!--   # q_gauge_sub = ls_discharge %>%  -->
<!--   #   filter(site_id == this_site_id) -->
<!--   #  -->
<!--   # q_ls_cf = q_ls_all %>%  -->
<!--   #   filter(cloud_free) -->

<!--   datemin = q_gauge$date %>% min() -->
<!--   datemax = q_gauge$date %>% max() -->

<!--   end_dates = seq.Date(from = datemin, to = datemax, by = 365)[-1] -->

<!--   min_start_date = datemin -->
<!--   max_start_date = datemax - 15 * 365 -->

<!--   if (min_start_date >= max_start_date) next -->

<!--   potential_start_date = calc_temporal_permutations(min_start_date, max_start_date) -->
<!--   max_years_ls = 15 -->

<!--   t1 = Sys.time() -->
<!--   tmp_ensemble = foreach(s = 1:length(potential_start_date), .combine = "bind_rows") %do% { -->

<!--     foreach(n = 1:max_years_ls, .combine = "bind_rows") %do% { -->

<!--       this_start_date = potential_start_date[s] -->
<!--       this_end_date = potential_start_date[s] + n * 365 -->

<!--       # q_gauge_fil = q_gauge %>%  -->
<!--       #   filter(date >= this_start_date, -->
<!--       #          date <= this_end_date) -->

<!--       q_gauge_fil = q_gauge %>%  -->
<!--         filter(date >= this_start_date, -->
<!--                date <= this_end_date) -->

<!--       # q_ls_all_fil = q_ls_all %>%  -->
<!--       #   filter(date >= this_start_date, -->
<!--       #          date <= this_end_date) -->
<!--       #  -->
<!--       # q_ls_cf_fil = q_ls_cf %>%  -->
<!--       #   filter(date >= this_start_date, -->
<!--       #          date <= this_end_date) -->

<!--       ks_none = tibble( -->
<!--         D = NA, -->
<!--         p.value = NA, -->
<!--         ks.boot.pvalue = NA -->
<!--       ) -->

<!--       if (nrow(q_gauge_fil) > 0) { -->
<!--         ks_sub_gauge = ks_stats(x = q_gauge_fil$discharge,  -->
<!--                          y = q_gauge$discharge, test = "wilcox.test") %>%  -->
<!--           mutate(type = "sub_gauge") -->
<!--       } else { -->
<!--         ks_sub_gauge = ks_none %>%  -->
<!--           mutate(type = "ls_cloud_free") -->
<!--       } -->

<!--       ks_sub_gauge %>%  -->
<!--         mutate(nyears = n,  -->
<!--                start_date = this_start_date, -->
<!--                end_date = this_end_date, -->
<!--                site_id = this_site_id) -->
<!--     } -->

<!--   } -->
<!--   if (i != 1) { -->
<!--     subgauge = bind_rows(subgauge, tmp_ensemble) -->
<!--   } else if (i == 1) { -->
<!--     subgauge = tmp_ensemble -->
<!--   } -->
<!--   print(paste0("time elapsed for station ", i, ": ", Sys.time() - t1)) -->
<!-- } -->

<!-- # save(result, file = "outputs/tmp_result_100sites.RData") -->
<!-- ``` -->


<!-- ## map the difference -->

<!-- ```{r} -->
<!-- subgauge = subgauge %>%  -->
<!--   mutate(nyears = factor(nyears)) %>%  -->
<!--   filter(!is.na(ks.boot.pvalue)) # remove those with no landsat obs -->

<!-- ratio_sig_diff_subgauge = subgauge %>%  -->
<!--   group_by(site_id, nyears, type) %>%  -->
<!--   summarise(r_sig_diff_test = sum(ks.boot.pvalue <= 0.05) / n(), -->
<!--             n = n()) %>%  -->
<!--   ungroup() -->

<!-- set.seed(2019) -->
<!-- D_fig = subgauge %>%  -->
<!--   select(site_id) %>%  -->
<!--   distinct() %>%  -->
<!--   sample_n(9) %>% -->
<!--   left_join(subgauge) %>%  -->
<!--   left_join(ratio_sig_diff_subgauge) %>%  -->
<!--   ggplot() + -->
<!--   geom_boxplot(aes(x = nyears, y = D, fill = r_sig_diff_test * 100)) + -->
<!--   facet_wrap(~site_id, scale = "free_y") + -->
<!--   scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 50, limits = c(0, 100), guide = guide_colorbar(title.position = "top", title.hjust = 0.5, barwidth = unit(80, units = "mm"), barheight = unit(5, units = "mm"), direction = "horizontal")) + -->
<!--   theme(legend.position = "bottom") + -->
<!--   labs(x = "Number of years of Landsat observation", -->
<!--        y = "D value", -->
<!--        fill = "% of ks.boot tests\nshowing significant (p < 0.05) difference", -->
<!--        lty = "Cloud filter") -->

<!-- D_fig -->

<!-- D_fig %>% -->
<!--   ggsave(filename = "figs/D_subgauge_fig9.png", -->
<!--          width = 8, -->
<!--          height = 6) -->


<!-- # set.seed(2019) -->
<!-- # result %>%  -->
<!-- #   select(site_id) %>%  -->
<!-- #   distinct() %>%  -->
<!-- #   sample_n(9) %>%  -->
<!-- #   left_join(result) %>% -->
<!-- #   ggplot() + -->
<!-- #   geom_boxplot(aes(x = nyears, y = ks.boot.pvalue, fill = type)) + -->
<!-- #   facet_wrap(~site_id) -->
<!-- ``` -->

<!-- ## map the gauge stations -->

<!-- ```{r} -->
<!-- site_stats = merged %>%  -->
<!--   group_by(site_id) %>%  -->
<!--   do({ -->
<!--     dat = . -->
<!--     dat_ls = dat %>% filter(!is.na(satellite)) -->
<!--     dat_ls_cf = dat_ls %>% filter(cloud_free == T) -->

<!--     ls_ls_all = ks_stats(dat$discharge, dat_ls$discharge) %>%  -->
<!--       mutate(source = "ls_all") -->
<!--     ls_ls_cf = ks_stats(dat$discharge, dat_ls_cf$discharge) %>%  -->
<!--       mutate(source = "ls_cfree") -->
<!--     bind_rows(ls_ls_all, ls_ls_cf) -->
<!--   }) %>%  -->
<!--   ungroup() -->

<!-- site_stats = site_stats %>%  -->
<!--   separate(site_id, into = c("X", "site_id"), sep = "X", remove = T, convert = T) %>% -->
<!--   mutate(site_id = sprintf("%08d", site_id)) %>%  -->
<!--   select(-X) -->

<!-- site_info = read_csv(file = "data/SiteAttributes.csv") %>%  -->
<!--   mutate(site_id = sprintf("%08d", site_no)) %>%  -->
<!--   select(lon = dec_long_va,  -->
<!--          lat = dec_lat_va, -->
<!--          site_id) %>%  -->
<!--   distinct() -->

<!-- site_stats_sf = site_stats %>%  -->
<!--   inner_join(site_info %>% st_as_sf(coords = c("lon", "lat"), crs = 4326), by = "site_id") %>%  -->
<!--   st_as_sf() -->

<!-- require(mapview) -->
<!-- mapview::mapView(site_stats_sf %>% filter(source == "ls_cfree", site_id == "02236125")) -->
<!-- ``` -->


<!-- ## try man-whitney test -->

<!-- ## pvalue wil-cox rank test -->